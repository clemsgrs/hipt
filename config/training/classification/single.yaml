data:
  train_csv: ''
  tune_csv: ''
  test_csv: ''

features_root_dir:
output_dir: 'output'
experiment_name: 'tcga_brca'
level: 'global'

# required when model.mask_attn_patch is True or model.mask_attn_region is True
region_dir: ''
spacing: 0.5
backend: 'asap'
region_format: "jpg"
attention_masks_dir:
seg_params:
  downsample: 16 # find the closest downsample level in the WSI for tissue segmentation computation
  sthresh: 8 # segmentation threshold (positive integer, using a higher threshold leads to less foreground and more background detection) (not used when use_otsu=True)
  mthresh: 7 # median filter size (positive, odd integer)
  close: 4 # additional morphological closing to apply following initial thresholding (positive integer)
  use_otsu: False # use otsu's method instead of simple binary thresholding
  tissue_pixel_value: 1 # value of tissue pixel in pre-computed segmentation masks

nepochs: 50
num_classes: 2
label_name: 'label'
label_mapping:
label_encoding:

task: 'classification'
loss: 'ce'
loss_options:
  num_classes: ${num_classes}

training:
  batch_size: 1
  pct:
  weighted_sampling: True
  gradient_accumulation: 32

augmentation:
  use: False
  name: 'random'
  kwargs:
      - gamma: 0.5
      - mean: 0.
      - std: 1.

tuning:
  batch_size: 1
  tune_every: 1

testing:
  retrieve_checkpoint: 'best'

model:
  embed_dim_patch: 384
  pretrain_vit_patch: 'checkpoints/vit_256_small_dino.pth'
  freeze_vit_patch: True
  freeze_vit_patch_pos_embed: True
  mask_attn_patch: False
  num_register_tokens_patch: 0
  embed_dim_region: 192
  pretrain_vit_region: 'checkpoints/vit_4096_xs_dino.pth'
  img_size_pretrained:
  freeze_vit_region: True
  freeze_vit_region_pos_embed: True
  mask_attn_region: False
  num_register_tokens_region: 0
  embed_dim_slide: 192
  region_size: 4096
  patch_size: 256
  mini_patch_size: 16
  dropout: 0.25
  agg_method: 'concat'
  slide_pos_embed:
    use: False
    learned: False
    type: '1d'
    max_seq_len: 512
    max_nslide: 21
    tile_size: ${model.region_size}

optim:
  name: 'adam'
  lr: 0.0002
  wd: 1e-5
  lr_scheduler:
    name: 'step'
    step_size: 20
    gamma: 0.5

early_stopping:
  enable: False
  tracking: 'loss'
  min_max: 'min'
  patience: 10
  min_epoch: 30
  save_all: False

speed:
  num_workers: 8

wandb:
  enable: True
  project: 'hipt'
  username: 'clemsg'
  exp_name: '${experiment_name}'
  tags:
  dir: '/home/user'
  to_log:
    - 'train': ['loss', 'auc', 'kappa']
    - 'tune': ['loss', 'auc', 'kappa', 'cm']
    - 'test': ['loss', 'auc', 'kappa', 'cm']
  group:
  resume_id:

hydra:
  run:
    dir: /tmp/hydra_output